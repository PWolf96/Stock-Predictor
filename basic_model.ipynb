{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data as web\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from finta import TA\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2010, 9, 1)\n",
    "end_date = datetime(2020, 8, 31)\n",
    "\n",
    "#invoke to_csv for df dataframe object from \n",
    "#DataReader method in the pandas_datareader library\n",
    "stock_df = web.DataReader(\"GOOGL\", 'yahoo', start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_balance_volume_creation(stock_df):\n",
    "    # Adding of on balance volume to dataframe\n",
    "    \n",
    "    new_df = pd.DataFrame({})\n",
    "\n",
    "    new_df = stock_df[['Adj Close']].copy()\n",
    "\n",
    "\n",
    "    new_balance_volume = [0]\n",
    "    tally = 0\n",
    "\n",
    "    for i in range(1, len(new_df)):\n",
    "        if (stock_df['Adj Close'][i] > stock_df['Adj Close'][i - 1]):\n",
    "            tally += stock_df['Volume'][i]\n",
    "        elif (stock_df['Adj Close'][i] < stock_df['Adj Close'][i - 1]):\n",
    "            tally -= stock_df['Volume'][i]\n",
    "        new_balance_volume.append(tally)\n",
    "\n",
    "    new_df['On_Balance_Volume'] = new_balance_volume\n",
    "    minimum = min(new_df['On_Balance_Volume'])\n",
    "\n",
    "    new_df['On_Balance_Volume'] = new_df['On_Balance_Volume'] - minimum\n",
    "    new_df['On_Balance_Volume'] = (new_df['On_Balance_Volume']+1).transform(np.log)\n",
    "\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema = TA.EMA(stock_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-09-01', '2010-09-02', '2010-09-03', '2010-09-07',\n",
       "               '2010-09-08', '2010-09-09', '2010-09-10', '2010-09-13',\n",
       "               '2010-09-14', '2010-09-15',\n",
       "               ...\n",
       "               '2020-08-18', '2020-08-19', '2020-08-20', '2020-08-21',\n",
       "               '2020-08-24', '2020-08-25', '2020-08-26', '2020-08-27',\n",
       "               '2020-08-28', '2020-08-31'],\n",
       "              dtype='datetime64[ns]', name='Date', length=2517, freq=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(new_df, stock_df):\n",
    "    # Adding of technical indicators to data frame (Exponential moving average and Bollinger Band)\n",
    "    edited_df = pd.DataFrame()\n",
    "\n",
    "    edited_df['open'] = stock_df['Open']\n",
    "    edited_df['high'] = stock_df['High']\n",
    "    edited_df['low'] = stock_df['Low']\n",
    "    edited_df['close'] = stock_df['Close']\n",
    "    edited_df['volume'] = stock_df['Volume']\n",
    "    edited_df.head()\n",
    "\n",
    "    ema = TA.EMA(edited_df)\n",
    "    bb = TA.BBANDS(edited_df)\n",
    "\n",
    "    new_df['Exponential_moving_average'] = ema.values\n",
    "\n",
    "    new_df = pd.concat([new_df, bb], axis = 1)\n",
    "\n",
    "\n",
    "    for i in range(19):\n",
    "        new_df['BB_MIDDLE'][i] = new_df.loc[i, 'Exponential_moving_average']\n",
    "    \n",
    "        if i != 0:\n",
    "            higher = new_df.loc[i, 'BB_MIDDLE'] + 2 * new_df['Adj Close'].rolling(i + 1).std()[i]\n",
    "            lower = new_df.loc[i, 'BB_MIDDLE'] - 2 * new_df['Adj Close'].rolling(i + 1).std()[i]\n",
    "            new_df['BB_UPPER'][i] = higher\n",
    "            new_df['BB_LOWER'][i] = lower\n",
    "        else:\n",
    "            new_df['BB_UPPER'][i] = new_df.loc[i, 'BB_MIDDLE']\n",
    "            new_df['BB_LOWER'][i] = new_df.loc[i, 'BB_MIDDLE']\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_preparation(new_df, train_split, history_points=21):\n",
    "    #Preparation of train test set.\n",
    "    train_indices = int(new_df.shape[0] * train_split)\n",
    "\n",
    "    train_data = new_df[:train_indices]\n",
    "    test_data = new_df[train_indices:]\n",
    "\n",
    "    test_data = test_data.reset_index()\n",
    "    test_data = test_data.drop(columns = ['index'])\n",
    "\n",
    "    normaliser = preprocessing.MinMaxScaler()\n",
    "    train_normalised_data = normaliser.fit_transform(train_data)\n",
    "\n",
    "    test_normalised_data = normaliser.transform(test_data)\n",
    "\n",
    "    X_train = np.array([train_normalised_data[:,0:][i : i + history_points].copy() for i in range(len(train_normalised_data) - history_points)])\n",
    "\n",
    "    y_train = np.array([train_normalised_data[:,0][i + history_points].copy() for i in range(len(train_normalised_data) - history_points)])\n",
    "    y_train = np.expand_dims(y_train, -1)\n",
    "\n",
    "    y_normaliser = preprocessing.MinMaxScaler()\n",
    "    next_day_close_values = np.array([train_data['Adj Close'][i + history_points].copy() for i in range(len(train_data) - history_points)])\n",
    "    next_day_close_values = np.expand_dims(next_day_close_values, -1)\n",
    "\n",
    "    y_normaliser.fit(next_day_close_values)\n",
    "\n",
    "     \n",
    "    X_test = np.array([test_normalised_data[:,0:][i  : i + history_points].copy() for i in range(len(test_normalised_data) - history_points)])\n",
    "    \n",
    "\n",
    "    y_test = np.array([test_data['Adj Close'][i + history_points].copy() for i in range(len(test_data) - history_points)])\n",
    "    \n",
    "    y_test = np.expand_dims(y_test, -1)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, y_normaliser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(X_train, y_train, history_points):\n",
    "    tf.random.set_seed(20)\n",
    "    np.random.seed(10)\n",
    "    lstm_input = Input(shape=(history_points, 6), name='lstm_input')\n",
    "\n",
    "    inputs = LSTM(21, name='first_layer')(lstm_input)\n",
    "    inputs = Dense(1, name='dense_layer')(inputs)\n",
    "    output = Activation('linear', name='output')(inputs)\n",
    "\n",
    "    model = Model(inputs=lstm_input, outputs=output)\n",
    "    adam = optimizers.Adam(lr = 0.0008)\n",
    "    model.compile(optimizer=adam, loss='mse')\n",
    "    model.fit(x=X_train, y=y_train, batch_size=15, epochs=170, shuffle=True, validation_split = 0.1)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Petar\\Desktop\\DataScience\\Udacity\\Capstone\\basic_model.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Petar/Desktop/DataScience/Udacity/Capstone/basic_model.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m history_points \u001b[39m=\u001b[39m \u001b[39m21\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Petar/Desktop/DataScience/Udacity/Capstone/basic_model.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m new_df \u001b[39m=\u001b[39m on_balance_volume_creation(stock_df)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Petar/Desktop/DataScience/Udacity/Capstone/basic_model.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m new_df \u001b[39m=\u001b[39m add_technical_indicators(new_df, stock_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Petar/Desktop/DataScience/Udacity/Capstone/basic_model.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m X_train, y_train, X_test, y_test, y_reverse_normaliser \u001b[39m=\u001b[39m train_test_split_preparation(new_df, train_split)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Petar/Desktop/DataScience/Udacity/Capstone/basic_model.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m model \u001b[39m=\u001b[39m lstm_model(X_train, y_train, history_points)\n",
      "\u001b[1;32mc:\\Users\\Petar\\Desktop\\DataScience\\Udacity\\Capstone\\basic_model.ipynb Cell 9\u001b[0m in \u001b[0;36madd_technical_indicators\u001b[1;34m(new_df, stock_df)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Petar/Desktop/DataScience/Udacity/Capstone/basic_model.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m new_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([new_df, bb], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Petar/Desktop/DataScience/Udacity/Capstone/basic_model.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m19\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Petar/Desktop/DataScience/Udacity/Capstone/basic_model.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     new_df[\u001b[39m'\u001b[39m\u001b[39mBB_MIDDLE\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39;49mloc[i, \u001b[39m'\u001b[39;49m\u001b[39mExponential_moving_average\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Petar/Desktop/DataScience/Udacity/Capstone/basic_model.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Petar/Desktop/DataScience/Udacity/Capstone/basic_model.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         higher \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39mBB_MIDDLE\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m new_df[\u001b[39m'\u001b[39m\u001b[39mAdj Close\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mrolling(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mstd()[i]\n",
      "File \u001b[1;32mc:\\Programs\\Python\\lib\\site-packages\\pandas\\core\\indexing.py:960\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    958\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(com\u001b[39m.\u001b[39mapply_if_callable(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[0;32m    959\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m--> 960\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_get_value(\u001b[39m*\u001b[39;49mkey, takeable\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_takeable)\n\u001b[0;32m    961\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programs\\Python\\lib\\site-packages\\pandas\\core\\frame.py:3622\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   3616\u001b[0m engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_engine\n\u001b[0;32m   3618\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   3619\u001b[0m     \u001b[39m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   3620\u001b[0m     \u001b[39m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   3621\u001b[0m     \u001b[39m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[1;32m-> 3622\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(index)\n\u001b[0;32m   3623\u001b[0m     \u001b[39mreturn\u001b[39;00m series\u001b[39m.\u001b[39m_values[row]\n\u001b[0;32m   3625\u001b[0m \u001b[39m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m \u001b[39m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programs\\Python\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:676\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindexer_at_time(key)\n\u001b[0;32m    674\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m     \u001b[39m# unrecognized type\u001b[39;00m\n\u001b[1;32m--> 676\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m    678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39mget_loc(\u001b[39mself\u001b[39m, key, method, tolerance)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "start_date = datetime(2010, 9, 1)\n",
    "end_date = datetime(2020, 8, 31)\n",
    "\n",
    "#invoke to_csv for df dataframe object from \n",
    "#DataReader method in the pandas_datareader library\n",
    "stock_df = web.DataReader(\"GOOGL\", 'yahoo', start_date, end_date)\n",
    "\n",
    "\n",
    "#pulling of google data from csv file\n",
    "#stock_df = pd.read_csv('./csv_files/google_stocks_data.csv')   #Note this data was pulled on 6 October 2020, some data may have changed since then \n",
    "\n",
    "train_split = 0.7\n",
    "\n",
    "history_points = 21\n",
    "\n",
    "new_df = on_balance_volume_creation(stock_df)\n",
    "\n",
    "new_df = add_technical_indicators(new_df, stock_df)\n",
    "\n",
    "X_train, y_train, X_test, y_test, y_reverse_normaliser = train_test_split_preparation(new_df, train_split)\n",
    "\n",
    "model = lstm_model(X_train, y_train, history_points)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_reverse_normaliser.inverse_transform(y_pred)\n",
    "\n",
    "real = plt.plot(y_test, label='Actual Price')\n",
    "pred = plt.plot(y_pred, label='Predicted Price')\n",
    "\n",
    "plt.gcf().set_size_inches(12, 8, forward=True)\n",
    "plt.title('Plot of real price and predicted price against number of days')\n",
    "plt.xlabel('Number of days')\n",
    "plt.ylabel('Adjusted Close Price($)')\n",
    "\n",
    "plt.legend(['Actual Price', 'Predicted Price'])\n",
    "\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "301da6f0e7e53b7955fa2d3d6c4b0305db26df81f353cd714eada29af4753e7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
